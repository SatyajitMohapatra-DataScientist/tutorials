{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a. Stream to Parquet\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the input stream to a set of parquet files. The purpose is to store the input stream to a log of raw events.\n",
    "\n",
    "![Model deployment with streaming Real-time operational Pipeline](../../assets/images/model-deployment-with-streaming.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch size (default 1024 records) are stored in a parquet file. The default output is to `/User/examples/model-deployment-with-streaming/data/events-pq`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import load_project\n",
    "from os import path\n",
    "\n",
    "project_path = path.abspath('conf')\n",
    "project = load_project(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the generated stream path, this is used to get the data which we store to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_stream = project.params.get('STREAM_CONFIGS').get('generated-stream')\n",
    "input_stream_path =  input_stream.get('path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuclio leverages consumer groups. When one or more Nuclio replicas join a consumer group, each replica receives its equal share of the shards, based on the number of replicas that are defined in the function.\n",
    "\n",
    "We set up the input stream URL below. A consumer-group URL is in the form of `http://v3io-webapi:8081/<container name>/<stream path>@<consumer group name>`. In this case we use `WEB_API_USERS` for URL prefix `http://v3io-webapi:8081/<container name>` and a consumer group named **`stream2pq`**.\n",
    "\n",
    "For more information, refer to the [Nuclio v3iostream trigger reference documentation](https://nuclio.io/docs/latest/reference/triggers/v3iostream/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input stream URL: http://v3io-webapi:8081/users/iguazio/examples/model-deployment-with-streaming/data/generated-stream@stream2pq\n"
     ]
    }
   ],
   "source": [
    "WEB_API_USERS = project.params.get('WEB_API_USERS')\n",
    "input_stream_url = path.join(WEB_API_USERS, input_stream_path) + \"@stream2pq\"\n",
    "print(f'Input stream URL: {input_stream_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the parquet files to the `target_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target path: /User/examples/model-deployment-with-streaming/data/events-pq\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "target_path = path.join(os.sep, 'v3io', project.params.get('CONTAINER'), project.params.get('PARQUET_TARGET_PATH'))\n",
    "print(f'Target path: {target_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting kind to 'nuclio'\n"
     ]
    }
   ],
   "source": [
    "# Define function spec\n",
    "%nuclio config kind = \"nuclio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "\n",
    "python -m pip install pandas\n",
    "python -m pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.build.baseImage to 'mlrun/ml-models'\n",
      "%nuclio: setting spec.readinessTimeoutSeconds to 200\n"
     ]
    }
   ],
   "source": [
    "%%nuclio config\n",
    "spec.build.baseImage = \"mlrun/ml-models\"\n",
    "spec.readinessTimeoutSeconds = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mounting volume path /User as ~/\n"
     ]
    }
   ],
   "source": [
    "%nuclio mount /User ~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_context(context):\n",
    "    setattr(context, 'batch', [])\n",
    "    setattr(context, 'batch_size', int(os.getenv('BATCH_SIZE', 1024)))\n",
    "    setattr(context, 'batch_count',int(os.getenv('BATCH_COUNT', 0)))\n",
    "    \n",
    "    pq_partitions = os.getenv('PQ_PARTITIONS')\n",
    "    if pq_partitions:\n",
    "        setattr(context, 'pq_partitions', pq_partitions.split(','))\n",
    "    else:\n",
    "        setattr(context, 'pq_partitions', pq_partitions)\n",
    "    \n",
    "    setattr(context, 'target_path', os.getenv('TARGET_PATH'))\n",
    "    os.makedirs(context.target_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context, event):\n",
    "    if type(event.body) is dict:\n",
    "        event_dict = event.body\n",
    "    else:\n",
    "        event_dict = json.loads(event.body)\n",
    "        \n",
    "    context.logger.info_with('Got invoked',\n",
    "                             trigger_kind=event.trigger.kind,\n",
    "                             event_body=event_dict)\n",
    "    \n",
    "    # add the incoming event to the current batch\n",
    "    context.batch.append(event_dict)\n",
    "    \n",
    "    #check if batch size reached\n",
    "    if context.batch_size == len(context.batch):\n",
    "        context.logger.info_with('Writing batch',\n",
    "                                 batch_count=context.batch_count,\n",
    "                                 batch_size=len(context.batch))\n",
    "        write_batch(context)\n",
    "        context.logger.info_with('Written batch',\n",
    "                                 batch_count=context.batch_count,\n",
    "                                 batch_size=len(context.batch))\n",
    "        \n",
    "def write_batch(context):\n",
    "    file_name = str(context.worker_id)+'_'+str(context.batch_count)\n",
    "    df = pd.DataFrame.from_records(context.batch)\n",
    "    df.to_parquet(path=os.path.join(context.target_path, file_name), partition_cols=context.pq_partitions)\n",
    "    # post write cleanup and counter update\n",
    "    context.batch = []\n",
    "    context.batch_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = {'TARGET_PATH' : target_path,\n",
    "        'BATCH_SIZE': 1024}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python> 2020-08-19 18:49:50,344 [info] Got invoked: {'trigger_kind': '', 'event_body': {'user_id': 1, 'event_type': 'spin'}}\n",
      "Python> 2020-08-19 18:49:50,344 [info] Got invoked: {'trigger_kind': '', 'event_body': {'user_id': 2, 'event_type': 'spin'}}\n",
      "Python> 2020-08-19 18:49:50,345 [info] Got invoked: {'trigger_kind': '', 'event_body': {'user_id': 3, 'event_type': 'spin'}}\n",
      "Python> 2020-08-19 18:49:50,345 [info] Got invoked: {'trigger_kind': '', 'event_body': {'user_id': 4, 'event_type': 'spin'}}\n",
      "Python> 2020-08-19 18:49:50,346 [info] Got invoked: {'trigger_kind': '', 'event_body': {'user_id': 5, 'event_type': 'spin'}}\n",
      "Python> 2020-08-19 18:49:50,346 [info] Got invoked: {'trigger_kind': '', 'event_body': {'user_id': 6, 'event_type': 'spin'}}\n",
      "Python> 2020-08-19 18:49:50,346 [info] Got invoked: {'trigger_kind': '', 'event_body': {'user_id': 7, 'event_type': 'spin'}}\n",
      "Python> 2020-08-19 18:49:50,347 [info] Got invoked: {'trigger_kind': '', 'event_body': {'user_id': 8, 'event_type': 'spin'}}\n",
      "Python> 2020-08-19 18:49:50,347 [info] Got invoked: {'trigger_kind': '', 'event_body': {'user_id': 9, 'event_type': 'spin'}}\n"
     ]
    }
   ],
   "source": [
    "for key, value in envs.items():\n",
    "    os.environ[key] = str(value)\n",
    "init_context(context)\n",
    "#reduce the batch size to 10\n",
    "context.batch_size = 10\n",
    "\n",
    "# trigger with 9 events:\n",
    "\n",
    "nine_events = [b'{\"user_id\" : 1 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 2 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 3 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 4 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 5 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 6 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 7 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 8 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 9 , \"event_type\": \"spin\"}']\n",
    "\n",
    "for e in nine_events:\n",
    "    event = nuclio.Event(body=e)\n",
    "    handler(context, event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n"
     ]
    }
   ],
   "source": [
    "# check whether a parquet has been created\n",
    "!ls -l {target_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python> 2020-08-19 18:49:50,952 [info] Got invoked: {'trigger_kind': '', 'event_body': {'user_id': 10, 'event_type': 'spin'}}\n",
      "Python> 2020-08-19 18:49:50,953 [info] Writing batch: {'batch_count': 0, 'batch_size': 10}\n",
      "Python> 2020-08-19 18:49:51,018 [info] Written batch: {'batch_count': 1, 'batch_size': 0}\n"
     ]
    }
   ],
   "source": [
    "# trigger the tenth event which should trigger the creation of the parquet file.\n",
    "tenth_event = b'{\"user_id\" : 10 , \"event_type\": \"spin\"}'\n",
    "event = nuclio.Event(body=tenth_event)\n",
    "handler(context, event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3\n",
      "-rw-r--r-- 1 51 nogroup 2268 Aug 19 18:49 None_0\n"
     ]
    }
   ],
   "source": [
    "# check weather a parquet has been created\n",
    "!ls -l {target_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "!rm {target_path}/None_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f583decac50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function\n",
    "\n",
    "gen_func = code_to_function(name='stream2pq', kind = 'nuclio')\n",
    "project.set_function(gen_func)\n",
    "stream2pq = project.func('stream2pq')\n",
    "stream2pq.set_envs(envs)\n",
    "stream2pq.add_trigger('stream2pq', nuclio.triggers.V3IOStreamTrigger(url=input_stream_url, access_key=os.getenv('V3IO_ACCESS_KEY'), maxWorkers=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-08-19 18:49:53,572 [info] deploy started\n",
      "[nuclio] 2020-08-19 18:49:54,659 (info) Staging files and preparing base images\n",
      "[nuclio] 2020-08-19 18:49:54,660 (info) Building processor image\n",
      "[nuclio] 2020-08-19 18:49:55,669 (info) Build complete\n",
      "[nuclio] 2020-08-19 18:49:59,704 (info) Function deploy complete\n",
      "[nuclio] 2020-08-19 18:49:59,709 done updating model-deployment-with-streaming-iguazio-stream2pq, function address: 3.131.87.251:31305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://3.131.87.251:31305'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build image\n",
    "stream2pq.deploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
