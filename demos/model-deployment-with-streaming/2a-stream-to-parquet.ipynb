{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a. Stream to Parquet\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the input stream to a set of parquet files. The purpose is to store the input stream to a log of raw events.\n",
    "\n",
    "![Model deployment with streaming Real-time operational Pipeline](../../assets/images/model-deployment-with-streaming.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch size (default 1024 records) are stored in a parquet file. The default output is to `/User/examples/model-deployment-with-streaming/data/events-pq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TARGET_PATH = os.path.join(os.sep, 'v3io', 'users', PARQUET_TARGET_PATH)\n",
    "input_stream_url = path.join(WEB_API_USERS, STREAM_CONFIGS['generated-stream']['path']) + \"@stream2pq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function spec\n",
    "%nuclio config kind = \"nuclio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "\n",
    "python -m pip install pandas\n",
    "python -m pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio config\n",
    "spec.build.baseImage = \"mlrun/ml-models\"\n",
    "spec.readinessTimeoutSeconds = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio mount /User ~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_context(context):\n",
    "    setattr(context, 'batch', [])\n",
    "    setattr(context, 'batch_size', int(os.getenv('BATCH_SIZE', 1024)))\n",
    "    setattr(context, 'batch_count',int(os.getenv('BATCH_COUNT', 0)))\n",
    "    \n",
    "    pq_partitions = os.getenv('PQ_PARTITIONS')\n",
    "    if pq_partitions:\n",
    "        setattr(context, 'pq_partitions', pq_partitions.split(','))\n",
    "    else:\n",
    "        setattr(context, 'pq_partitions', pq_partitions)\n",
    "    \n",
    "    setattr(context, 'target_path', os.getenv('TARGET_PATH'))\n",
    "    os.makedirs(context.target_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context, event):\n",
    "    if type(event.body) is dict:\n",
    "        event_dict = event.body\n",
    "    else:\n",
    "        event_dict = json.loads(event.body)\n",
    "        \n",
    "    context.logger.info_with('Got invoked',\n",
    "                             trigger_kind=event.trigger.kind,\n",
    "                             event_body=event_dict)\n",
    "    \n",
    "    # add the incoming event to the current batch\n",
    "    context.batch.append(event_dict)\n",
    "    \n",
    "    #check if batch size reached\n",
    "    if context.batch_size == len(context.batch):\n",
    "        context.logger.info_with('Writing batch',\n",
    "                                 batch_count=context.batch_count,\n",
    "                                 batch_size=len(context.batch))\n",
    "        write_batch(context)\n",
    "        context.logger.info_with('Written batch',\n",
    "                                 batch_count=context.batch_count,\n",
    "                                 batch_size=len(context.batch))\n",
    "        \n",
    "def write_batch(context):\n",
    "    file_name = str(context.worker_id)+'_'+str(context.batch_count)\n",
    "    df = pd.DataFrame.from_records(context.batch)\n",
    "    df.to_parquet(path=os.path.join(context.target_path, file_name), partition_cols=context.pq_partitions)\n",
    "    # post write cleanup and counter update\n",
    "    context.batch = []\n",
    "    context.batch_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_context(context)\n",
    "#reduce the batch size to 10\n",
    "context.batch_size = 10\n",
    "\n",
    "# trigger with 9 events:\n",
    "\n",
    "nine_events = [b'{\"user_id\" : 1 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 2 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 3 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 4 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 5 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 6 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 7 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 8 , \"event_type\": \"spin\"}',\n",
    "              b'{\"user_id\" : 9 , \"event_type\": \"spin\"}']\n",
    "\n",
    "for e in nine_events:\n",
    "    event = nuclio.Event(body=e)\n",
    "    handler(context, event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether a parquet has been created\n",
    "!ls -l {TARGET_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigger the tenth event which should trigger the creation of the parquet file.\n",
    "tenth_event = b'{\"user_id\" : 10 , \"event_type\": \"spin\"}'\n",
    "event = nuclio.Event(body=tenth_event)\n",
    "handler(context, event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check weather a parquet has been created\n",
    "!ls -l {TARGET_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "!rm {TARGET_PATH}/None_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLRUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r project_name\n",
    "%store -r project_path\n",
    "%store -r artifact_path\n",
    "%store -r project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import code_to_function\n",
    "\n",
    "gen_func = code_to_function(name='stream2pq', kind = 'nuclio')\n",
    "project.set_function(gen_func)\n",
    "stream2pq = project.func('stream2pq')\n",
    "stream2pq.set_envs({'TARGET_PATH' : TARGET_PATH, 'BATCH_SIZE': 1024})\n",
    "stream2pq.add_trigger('stream2pq', nuclio.triggers.V3IOStreamTrigger(url=input_stream_url, access_key=V3IO_ACCESS_KEY,maxWorkers=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build image\n",
    "stream2pq.deploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
